{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NogginBops/DD2363_VT23/blob/main/Lab1/report_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 1: Matrix Factorization**\n",
        "**Julius Häger**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Short summary of the lab report. State the objectives, methods used, main results and conlusions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJipbXtnjrJZ"
      },
      "source": [
        "The goal of this Lab is to build procedures for some common linear algebra operations and functions. The procedures presented are, sparse matrix-vector product, QR factorization using the Householder reflection method, direct solver for Ax=b, and blocked matrix-matrix product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2858d288-36ea-4c50-a152-100531c9db63"
      },
      "source": [
        "\"\"\"This program is lab report in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2023 Julius Häger (juliusha@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, Math\n",
        "\n",
        "#try:\n",
        "#    from dolfin import *; from mshr import *\n",
        "#except ImportError as e:\n",
        "#    !apt-get install -y -qq software-properties-common \n",
        "#    !add-apt-repository -y ppa:fenics-packages/fenics\n",
        "#    !apt-get update -qq\n",
        "#    !apt install -y --no-install-recommends fenics\n",
        "#    from dolfin import *; from mshr import *\n",
        "    \n",
        "#import dolfin.common.plotting as fenicsplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Converts a sparse (CRS) matrix from a dense representation\n",
        "def sparse_from_dense(matrix):\n",
        "  val = []\n",
        "  col_idx = []\n",
        "  row_ptr = [0]\n",
        "\n",
        "  count = 0\n",
        "  for r, row in enumerate(matrix):\n",
        "    for c, v in enumerate(row):\n",
        "      if (v != 0):\n",
        "        count += 1;\n",
        "        val.append(v)\n",
        "        col_idx.append(c)\n",
        "    row_ptr.append(count)\n",
        "  return SparseMatrix(np.array(val, dtype=matrix.dtype), col_idx, row_ptr)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "To represent sparse matrices a compressed row storage (CRS) can be used to reduce the memory footprint of the matrix[TODO]. This introduces a need for a modified matrix-vector procedure that can take advantage of the CRS form of the matrix. This algorithm should ideally not consider any elements of the matrix that contains zeros, and as such has potential to be more efficient.\n",
        "\n",
        "It is known that any real square matrix $A$ can be decomposed into as follows $A=QR$ where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix. There are three well known algorithms for calculating this factorization, use that uses the Gram-Schmidt process, one that uses Householder reflections, and one that uses Givens rotations. In this report the method using Householder reflections will be presented.\n",
        "\n",
        "Solving systems of linear equations of the form $Ax=b$ is a common operation when doing various simulations. A direct solver proceduce using QR decomposition will be presented.\n",
        "\n",
        "As computers get progressively faster at floating point opreations memory access speed is being left behind. This means that for some algorithms computational time complexity doesn't dominate program time, instead the computer is left waiting for main memory reads. This issue is especially common when multiplying large matrices as using a naïve method for multiplication results in many duplicated memory accesses and for large matrices that don't fit in the processor cache this can cause a lot of cache misses which increase the time of all of the memory accesses. This problem can be mitigated by increasing the computational intensity of the algorithm used. In this report a blocked matrix-matrix multiplication procedure will be presented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 1: Sparse Matrix-Vector product"
      ],
      "metadata": {
        "id": "lgT1y4-b9a2p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4iBj5VURZx"
      },
      "source": [
        "To represent compressed row storage of matrices the following defintion is used:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseMatrix:\n",
        "  def __init__(self, val, col_idx, row_ptr):\n",
        "    self.val = val\n",
        "    self.col_idx = col_idx\n",
        "    self.row_ptr = row_ptr"
      ],
      "metadata": {
        "id": "5Lw0ClaG6eOZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where `val` contains is an array is the non-zero elements of the matrix, `col_idx` is an array that corresponds to the `val` array and specifies in that column that value is found in. `row_ptr` contains indices into `val` and `col_idx` that specify the start and end position of each row.\n",
        "\n",
        "To implement the sparse matrix-vector product we go through non-zero values of each row of the matrix and use `col_idx` to look up the corresponding value in the vector."
      ],
      "metadata": {
        "id": "49hZxvkQ63LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 1. Function: sparse matrix-vector product\n",
        "\n",
        "def sparse_matrix_vector_product(matrix, vector):\n",
        "  res = np.zeros(len(vector), dtype=np.result_type(matrix.val, vector))\n",
        "  for i in range(len(res)):\n",
        "    for j in range(matrix.row_ptr[i], matrix.row_ptr[i+1]):\n",
        "      res[i] = res[i] + matrix.val[j] * vector[matrix.col_idx[j]]\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "1IC42xsnBmEM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that this procedure produces correct results we can compare this to NumPy's built in matrix-vector product procedure, as this procedure has a high likeliehood of being correct as it is widely used."
      ],
      "metadata": {
        "id": "gwcQJQ3f7wzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 1. Tests\n",
        "\n",
        "dense = np.array([[3.0, 2, 0, 2, 0, 0],\\\n",
        "                  [0, 2, 1, 0, 0, 0],\\\n",
        "                  [0, 0, 1, 0, 0, 0],\\\n",
        "                  [0, 0, 3, 2, 0, 0],\\\n",
        "                  [0, 0, 0, 0, 1, 0],\\\n",
        "                  [0, 0, 0, 0, 2, 3]])\n",
        "\n",
        "matrix = sparse_from_dense(dense)\n",
        "\n",
        "vector = np.array([1, 1, 1, 1, 1, 1])\n",
        "\n",
        "print(sparse_matrix_vector_product(matrix, vector))\n",
        "\n",
        "print(dense @ vector)"
      ],
      "metadata": {
        "id": "t2C63BH8C_sh",
        "outputId": "96b46f3b-0d51-49d1-cff3-a71a54bc83e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7. 3. 1. 5. 1. 5.]\n",
            "[7. 3. 1. 5. 1. 5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2: QR factorization "
      ],
      "metadata": {
        "id": "_Am8e3q_9ETG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplicity of the Gram-Schmidt algorithm is very appealing, but it is inherently numerically unstable. Householder reflections are a lot more numerically stable, at the cost of a more complicated implementation. Compared to other numerically stable algorithms such as Givens rotations Householder reflections are not as easily parallelizable and have higher bandwidth requirements. But as the algorithm presented here is not going to be parallelized nor run on large matrices I have determined that Householder reflections are going to be sufficient."
      ],
      "metadata": {
        "id": "bIMbknLW9Y0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 2. Function: QR factorization\n",
        "\n",
        "# FIXME: Reference the error in the course book algorithm. And reference this also:\n",
        "# http://mlwiki.org/index.php/Householder_Transformation\n",
        "\n",
        "def qr_householder(matrix):\n",
        "  n = matrix.shape[0]\n",
        "  A = matrix.copy().astype(float)\n",
        "  Q = np.identity(n)\n",
        "  for k in range(n - 1):\n",
        "    x = A[k:n, k]\n",
        "    v_k = x.copy()\n",
        "    norm = np.linalg.norm(x)\n",
        "    s = -np.sign(x[0])\n",
        "    v_k[0] = v_k[0] - s*norm\n",
        "    v_k = v_k/np.linalg.norm(v_k)\n",
        "    for m in range(k, n):\n",
        "      A[k:n,m] = A[k:n,m] - (2 * v_k * np.dot(v_k, A[k:n,m]))\n",
        "    \n",
        "    v_kT = np.transpose(np.atleast_2d(v_k))\n",
        "    I = np.identity(k)\n",
        "    F_k = np.identity(n - k) - 2 * ((v_k * v_kT) / np.dot(v_k, v_k))\n",
        "    Z = np.zeros((k, n - k))\n",
        "    Q_kT = np.block([[I, Z], [np.transpose(Z), np.transpose(F_k)]])\n",
        "    Q =  Q @ Q_kT\n",
        "\n",
        "  return Q, A"
      ],
      "metadata": {
        "id": "1dHJqK9ZNHGN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify this algorithm we can check that $R$ is in fact an upper triangular matrix. We can also check the Frobenius norms $|| Q^TQ - I||_F$ which should be $0$ if $Q$ is an orthogonal matrix (note that $Q^T = Q^{-1}$ for orthogonal matrices). We can also look at the Fronebious norm $|| QR - A ||_F$ to verify that composing $Q$ and $R$ does indeed give us $A$.\n",
        "\n",
        "When checking if $R$ is actually triangular we use an epsilon $\\epsilon = 1\\times10^{-15}$ to compensate for the floating point errors that happen which causes some of the lower elements of the array to be not exactly zero but very close to it."
      ],
      "metadata": {
        "id": "yHRXj-gqBgJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 2. Tests\n",
        "\n",
        "def is_upper_triangular(matrix):\n",
        "  m, n = matrix.shape\n",
        "  for row in range(m):\n",
        "    for col in range(n):\n",
        "      if col < row:\n",
        "        if matrix[row, col] > 1e-15:\n",
        "          return False\n",
        "  return True\n",
        "\n",
        "Q, R = qr_householder(dense)\n",
        "\n",
        "print(f\"R is upper triangular: {is_upper_triangular(R)}\")\n",
        "\n",
        "norm_fro = np.linalg.norm(Q@R - dense, ord = 'fro')\n",
        "display(Math(rf'|| QR - A ||_F = {norm_fro}'))\n",
        "\n",
        "norm_fro = np.linalg.norm((np.transpose(Q) @ Q) - np.eye(*Q.shape), ord = 'fro')\n",
        "display(Math(rf'|| Q^TQ - I ||_F = {norm_fro}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "AFzBCIxIuXhI",
        "outputId": "c43ce7a6-bfcc-4588-d955-c683b1597fb7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R is upper triangular: True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle || QR - A ||_F = 2.4828289594291222e-15$"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle || Q^TQ - I ||_F = 3.5062941296016293e-16$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve $Ax = b$ it is possible to calculate the inverse of $A$ and rewrite the equation as $x = A^{-1}b$ from which $x$ can be directly calculated. Calculating the inverse of a general matrix $A$ can be quite involved, so instead we can use the QR-factorization we just created to simplify this task. We can rearrange the equation as follows:\n",
        "$$\n",
        "\\begin{align*}\n",
        "Ax&=b\\\\\n",
        "QRx&=b\\quad\\text{(using $A=QR$)}\\\\\n",
        "Rx&=Q^Tb\\quad\\text{(using $Q^{-1} = Q^T$ and multiplying from the left)}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "This form is much easier to solve as you easily do the $Q^Tb$ matrix-vector product and then you are left with $Rx = b'$ which can easily be solved with backwards substitusion as $R$ in an upper triangular matrix.\n",
        "\n",
        "And so the algorithm consists of first QR-factorizing the matrix $A$ and then doing the multiplication $b' = Q^Tb$ follwed by backwards-substitution to solve $Rx = b'$."
      ],
      "metadata": {
        "id": "tg9CuXtNDciE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 3. Function: direct solver Ax=b\n",
        "\n",
        "def backward_substitution(U, b):\n",
        "  n = U.shape[0]\n",
        "  x = np.zeros(n)\n",
        "  x[n - 1] = b[n - 1] / U[n - 1, n - 1]\n",
        "  for i in range(n - 2, -1, -1):\n",
        "    sum = 0\n",
        "    for j in range(i + 1, n):\n",
        "      sum += U[i, j] * x[j]\n",
        "    x[i] = (b[i] - sum) / U[i, i]\n",
        "  \n",
        "  return x\n",
        "\n",
        "def solve(A, b):\n",
        "  Q2, R2 = np.linalg.qr(A)\n",
        "  Q, R = qr_householder(A)\n",
        "  b_q = np.transpose(Q) @ b\n",
        "  x = backward_substitution(R, b_q)\n",
        "  return x"
      ],
      "metadata": {
        "id": "iEjFDHqxpKuu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test that this procedure works as it should we can verify that $Ax = b$ by checking that $|| Ax - b || = 0$. We can also check the computed result against a algorithmically calculated solution. In this case the solution to the following system of linear equations can be calcualted to be $\\left[ \\frac{1}{5}, \\frac{3}{35} \\right]^T$:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "2 & 7 \\\\\n",
        "5 & 0\n",
        "\\end{bmatrix}\n",
        "x\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 \\\\\n",
        "1\n",
        "\\end{bmatrix}\\\\\n",
        "x=\\begin{bmatrix}\n",
        "\\frac{1}{5} \\\\\n",
        "\\frac{3}{35}\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "dI0XKb_NF80d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment 3. Tests\n",
        "\n",
        "m = np.array([[2, 7], [5, 0]])\n",
        "b = np.array([1, 1])\n",
        "\n",
        "x = solve(m, b)\n",
        "\n",
        "x_actual = np.array([ 1 / 5.0, 3 / 35.0 ])\n",
        "\n",
        "diff = np.linalg.norm((m @ x) - b)\n",
        "display(Math(rf'|| Ax - b || = {diff}'))\n",
        "\n",
        "diff_actual = np.linalg.norm(x - x_actual)\n",
        "display(Math(rf'|| x - y || = {diff_actual}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "MDAx4ULDulwS",
        "outputId": "c79dab31-5b85-47bd-9179-d2b1011f0045"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle || Ax - b || = 1.1102230246251565e-16$"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle || x - y || = 1.3877787807814457e-17$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LnTuP-15ICRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Extra Assignment. Blocked Matrix-Matrix product\n",
        "\n",
        "def blocked_matrix_matrix_product(A, B):\n",
        "  M = 2\n",
        "  N = 2\n",
        "  P = 2\n",
        "\n",
        "  m, p = A.shape\n",
        "  _, n = B.shape\n",
        "  bm = int(np.ceil(m / M))\n",
        "  bn = int(np.ceil(n / N))\n",
        "  bp = int(np.ceil(p / P))\n",
        "\n",
        "  C = np.zeros((m, n))\n",
        "\n",
        "  for i in range(0, M):\n",
        "    for j in range(0, N):\n",
        "      for k in range(0, P):\n",
        "        ib = i * bm\n",
        "        jb = j * bn\n",
        "        kb = k * bp\n",
        "        A_b = A[ib:ib+bm, kb:kb+bp]\n",
        "        B_b = B[kb:kb+bp, jb:jb+bn]\n",
        "        C[ib:ib+bm,jb:jb+bn] = C[ib:ib+bm,jb:jb+bn] + (A_b @ B_b)\n",
        "        \n",
        "\n",
        "  return C"
      ],
      "metadata": {
        "id": "HHSthCgwzhq3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extra Assignment. Tests\n",
        "\n",
        "A = np.array([[1.0, 2, 3, 4, 1], \\\n",
        "              [5, 6, 7, 8, 1], \\\n",
        "              [9, 1, 2, 3, 1], \\\n",
        "              [4, 5, 6, 7, 1]])\n",
        "\n",
        "B = np.array([[1.0, 2], \\\n",
        "              [5, 6], \\\n",
        "              [9, 1], \\\n",
        "              [4, 5], \\\n",
        "              [1, 1]])\n",
        "\n",
        "\n",
        "print(A)\n",
        "print(B)\n",
        "\n",
        "AB = blocked_matrix_matrix_product(A, B)\n",
        "\n",
        "print(\"AB:\", AB)\n",
        "print(\"A@B\", A@B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOE51zxU4SS6",
        "outputId": "717b5c33-5920-41a1-c96d-0d4c45e494da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2. 3. 4. 1.]\n",
            " [5. 6. 7. 8. 1.]\n",
            " [9. 1. 2. 3. 1.]\n",
            " [4. 5. 6. 7. 1.]]\n",
            "[[1. 2.]\n",
            " [5. 6.]\n",
            " [9. 1.]\n",
            " [4. 5.]\n",
            " [1. 1.]]\n",
            "AB: [[ 55.  38.]\n",
            " [131.  94.]\n",
            " [ 45.  42.]\n",
            " [112.  80.]]\n",
            "A@B [[ 55.  38.]\n",
            " [131.  94.]\n",
            " [ 45.  42.]\n",
            " [112.  80.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "Present the results. If the result is an algorithm that you have described under the *Methods* section, you can present the data from verification and performance tests in this section. If the result is the output from a computational experiment this is where you present a selection of that data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "Summarize your results and your conclusions. Were the results expected or surprising. Do your results have implications outside the particular problem investigated in this report? "
      ]
    }
  ]
}